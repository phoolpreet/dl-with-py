{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 14:03:33.542970: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-30 14:03:33.556029: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 14:03:33.634433: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-30 14:03:33.700245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 14:03:33.756251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 14:03:33.773536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 14:03:33.917588: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 14:03:35.214920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import shutil, os, pathlib\n",
    "import random\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data/pets/images/\"\n",
    "target_dir = \"data/pets/annotations/trimaps/\"\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "target_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7390, 200, 200, 3)\n",
      "(7390, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "img_size = (200, 200)\n",
    "num_imgs = len(input_img_paths)\n",
    "random.Random(1337).shuffle(input_img_paths)\n",
    "random.Random(1337).shuffle(target_paths)\n",
    "\n",
    "\n",
    "def path_to_input_image(path):\n",
    "    return img_to_array(load_img(path, target_size=img_size))\n",
    "\n",
    "\n",
    "def path_to_target(path):\n",
    "    img = img_to_array(load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
    "    img = img.astype(\"uint8\") - 1\n",
    "    return img\n",
    "\n",
    "\n",
    "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
    "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
    "for i in range(num_imgs):\n",
    "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
    "    targets[i] = path_to_target(target_paths[i])\n",
    "\n",
    "print(input_imgs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_samples = 1000\n",
    "train_input_imgs = input_imgs[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_input_imgs = input_imgs[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class SegModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SegModel, self).__init__()\n",
    "        l1 = tf.keras.layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")\n",
    "        l2 = tf.keras.layers.Conv2D(64, 3, strides=1, activation=\"relu\", padding=\"same\")\n",
    "        l3 = tf.keras.layers.Conv2D(\n",
    "            128, 3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l4 = tf.keras.layers.Conv2D(\n",
    "            128, 3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l5 = tf.keras.layers.Conv2D(\n",
    "            256, 3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l6 = tf.keras.layers.Conv2D(\n",
    "            256, 3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l7 = tf.keras.layers.Conv2DTranspose(\n",
    "            256, 3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l8 = tf.keras.layers.Conv2DTranspose(\n",
    "            256, 3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l9 = tf.keras.layers.Conv2DTranspose(\n",
    "            128, 3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l10 = tf.keras.layers.Conv2DTranspose(\n",
    "            128, 3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l11 = tf.keras.layers.Conv2DTranspose(\n",
    "            64, 3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        l12 = tf.keras.layers.Conv2DTranspose(\n",
    "            64, 3, strides=2, activation=\"relu\", padding=\"same\"\n",
    "        )\n",
    "        self.layers_list = [l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for l in self.layers_list:\n",
    "            z = l(z)\n",
    "        return z\n",
    "\n",
    "model = SegModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"data/model_checkpoints/oxford_segmentation.keras\", save_best_only=True)\n",
    "]\n",
    "history = model.fit(\n",
    "    train_input_imgs,\n",
    "    train_targets,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    batch_size=64,\n",
    "    validation_data=(val_input_imgs, val_targets),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
